{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6a12fa-6e99-4c88-a89d-319aa1595b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA 622 - Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4555b7aa-edc1-46e4-b5c7-ea913ddc908d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Hours_Studied  Attendance Parental_Involvement Access_to_Resources  \\\n",
      "0             23          84                  Low                High   \n",
      "1             19          64                  Low              Medium   \n",
      "2             24          98               Medium              Medium   \n",
      "3             29          89                  Low              Medium   \n",
      "4             19          92               Medium              Medium   \n",
      "\n",
      "  Extracurricular_Activities  Sleep_Hours  Previous_Scores Motivation_Level  \\\n",
      "0                         No            7               73              Low   \n",
      "1                         No            8               59              Low   \n",
      "2                        Yes            7               91           Medium   \n",
      "3                        Yes            8               98           Medium   \n",
      "4                        Yes            6               65           Medium   \n",
      "\n",
      "  Internet_Access  Tutoring_Sessions Family_Income Teacher_Quality  \\\n",
      "0             Yes                  0           Low          Medium   \n",
      "1             Yes                  2        Medium          Medium   \n",
      "2             Yes                  2        Medium          Medium   \n",
      "3             Yes                  1        Medium          Medium   \n",
      "4             Yes                  3        Medium            High   \n",
      "\n",
      "  School_Type Peer_Influence  Physical_Activity Learning_Disabilities  \\\n",
      "0      Public       Positive                  3                    No   \n",
      "1      Public       Negative                  4                    No   \n",
      "2      Public        Neutral                  4                    No   \n",
      "3      Public       Negative                  4                    No   \n",
      "4      Public        Neutral                  4                    No   \n",
      "\n",
      "  Parental_Education_Level Distance_from_Home  Gender  Exam_Score  \n",
      "0              High School               Near    Male          67  \n",
      "1                  College           Moderate  Female          61  \n",
      "2             Postgraduate               Near    Male          74  \n",
      "3              High School           Moderate    Male          71  \n",
      "4                  College               Near  Female          70  \n",
      "   Math_Score  Reading_Score  Writing_Score  Placement_Score  Club_Join_Date\n",
      "0          65             86             67               78            2021\n",
      "1          64             85             71               80            2019\n",
      "2          76             77             77               84            2021\n",
      "3          80             76             75               75            2021\n",
      "4          63             91             62               90            2019\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "\n",
    "# loading both dataset\n",
    "dataset1_url = \"https://raw.githubusercontent.com/hbedros/data622-assignment1/refs/heads/main/data/dataset-1.csv\"\n",
    "dataset2_url = \"https://raw.githubusercontent.com/hbedros/data622-assignment1/refs/heads/main/data/dataset-2.csv\"\n",
    "\n",
    "dataset1 = pd.read_csv(dataset1_url)\n",
    "dataset2 = pd.read_csv(dataset2_url)\n",
    "\n",
    "print(dataset1.head())\n",
    "print(dataset2.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7243e561",
   "metadata": {},
   "source": [
    "### Overview of the Datasets\n",
    "\n",
    "We have two datasets to work with:\n",
    "\n",
    "1. **Dataset 1 (dataset1.csv)**:\n",
    "   - This one has a bunch of columns about students, like how many hours they studied, their attendance, and stuff like that.\n",
    "   - It also includes some categories, like whether they had access to resources or if they were involved in extracurricular activities.\n",
    "   - Overall, it gives a good picture of their backgrounds and behaviors.\n",
    "\n",
    "2. **Dataset 2 (dataset2.csv)**:\n",
    "   - This dataset focuses on the actual scores: Math, Reading, Writing, and a Placement Score.\n",
    "   - It’s more about the outcomes of their studies.\n",
    "\n",
    "### Similarities and Differences\n",
    "\n",
    "**Similarities**:\n",
    "- Both datasets deal with students and their academic stuff.\n",
    "- They relate to how students perform in school, which is super relevant for the analysis.\n",
    "\n",
    "**Differences**:\n",
    "- Dataset 1 has a lot more details about students' experiences and environments.\n",
    "- Dataset 2 is mainly about their scores, so it’s smaller and focused just on performance.\n",
    "\n",
    "### Analyzing the Data\n",
    "\n",
    "For the analysis, we can aim to predict how well students will do (like their scores) based on the info in Dataset 1. \n",
    "\n",
    "### Which Algorithms to Use\n",
    "\n",
    "Here are a couple of machine learning algorithms that could work well:\n",
    "\n",
    "1. **Linear Regression**:\n",
    "   - This is good for predicting scores since it looks at relationships between things (like how study hours might affect scores).\n",
    "\n",
    "2. **Random Forest Regression**:\n",
    "   - This one’s a bit more complex and can handle a mix of numbers and categories. It's great if we think there might be non-linear relationships between the factors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5650de36-c4da-453b-86cc-1b02e9ac304b",
   "metadata": {},
   "source": [
    "### Exploratory Analysis Report\n",
    "\n",
    "## Matt's Role - Large Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a450fe51-24f4-40f6-af5c-c91ff40bac2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Join Date</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Join Date  Frequency\n",
       "0       2019        102\n",
       "1       2018        101\n",
       "2       2020         99\n",
       "3       2021         97"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "club_join_freq = dataset2['Club_Join_Date'].value_counts()\n",
    "club_join_freq = pd.DataFrame(club_join_freq)\n",
    "club_join_freq = club_join_freq.reset_index()\n",
    "club_join_freq.columns = ['Join Date', 'Frequency']\n",
    "display(club_join_freq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493e8765-d9b7-47e6-81fe-1e321568c0ab",
   "metadata": {},
   "source": [
    "The distribution of individuals who joined the club throughout the years is rather equivalent, with the highest frequency of enrollments being in 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5749bede-1afd-473c-8ccd-c5e36c3b0e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Club_Join_Date</th>\n",
       "      <th>Math_Score_mean</th>\n",
       "      <th>Reading_Score_mean</th>\n",
       "      <th>Writing_Score_mean</th>\n",
       "      <th>Placement_Score_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>79.168317</td>\n",
       "      <td>80.267327</td>\n",
       "      <td>79.396040</td>\n",
       "      <td>80.128713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>78.941176</td>\n",
       "      <td>80.088235</td>\n",
       "      <td>79.931373</td>\n",
       "      <td>80.254902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>79.262626</td>\n",
       "      <td>80.949495</td>\n",
       "      <td>78.878788</td>\n",
       "      <td>81.494949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>79.371134</td>\n",
       "      <td>77.350515</td>\n",
       "      <td>78.422680</td>\n",
       "      <td>79.494845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Club_Join_Date  Math_Score_mean  Reading_Score_mean  Writing_Score_mean  \\\n",
       "0            2018        79.168317           80.267327           79.396040   \n",
       "1            2019        78.941176           80.088235           79.931373   \n",
       "2            2020        79.262626           80.949495           78.878788   \n",
       "3            2021        79.371134           77.350515           78.422680   \n",
       "\n",
       "   Placement_Score_mean  \n",
       "0             80.128713  \n",
       "1             80.254902  \n",
       "2             81.494949  \n",
       "3             79.494845  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'subplots'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m Means \u001b[38;5;241m=\u001b[39m Means\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m      8\u001b[0m display(Means)\n\u001b[1;32m---> 10\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubplots\u001b[49m(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m,\u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m     12\u001b[0m ax\u001b[38;5;241m.\u001b[39mplot(Means[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClub_Join_Date\u001b[39m\u001b[38;5;124m'\u001b[39m], Means[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMath_Score_mean\u001b[39m\u001b[38;5;124m'\u001b[39m], label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Math Score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m ax\u001b[38;5;241m.\u001b[39mplot(Means[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClub_Join_Date\u001b[39m\u001b[38;5;124m'\u001b[39m], Means[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWriting_Score_mean\u001b[39m\u001b[38;5;124m'\u001b[39m], label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Writing Score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\daacs\\.venv\\Lib\\site-packages\\matplotlib\\_api\\__init__.py:217\u001b[0m, in \u001b[0;36mcaching_module_getattr.<locals>.__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m props:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m props[name]\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance)\n\u001b[1;32m--> 217\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'subplots'"
     ]
    }
   ],
   "source": [
    "dataset2 = dataset2.sort_values(by = ['Club_Join_Date'])\n",
    "\n",
    "Means = dataset2.groupby(['Club_Join_Date']).agg(['mean'])\n",
    "Means.columns = ['_'.join(col).strip() for col in Means.columns]\n",
    "\n",
    "Means = Means.reset_index()\n",
    "\n",
    "display(Means)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "\n",
    "ax.plot(Means['Club_Join_Date'], Means['Math_Score_mean'], label = \"Mean Math Score\")\n",
    "ax.plot(Means['Club_Join_Date'], Means['Writing_Score_mean'], label = \"Mean Writing Score\")\n",
    "ax.plot(Means['Club_Join_Date'], Means['Placement_Score_mean'], label = \"Mean Placement Score\")\n",
    "\n",
    "ax.set_xticks(Means['Club_Join_Date'])\n",
    "\n",
    "plt.xlabel('Time in Years')\n",
    "plt.ylabel('Mean Scores')\n",
    "plt.title('Changes in Mean Scores Over Time')\n",
    "plt.legend(bbox_to_anchor=(1,1), loc = 'center left')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9d6fe9-3f73-4af5-8fdb-fb649ea193ce",
   "metadata": {},
   "source": [
    "We can see that average scores are rather consistent throughout the years and they tend to fluctuate between 79 through 81. Interestingly, writing and placement scores appear to decrease quite a bit in 2021. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb419d8b-42be-4804-a4c0-0fc85f5b9349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Math_Score  Reading_Score  Writing_Score  Placement_Score  \\\n",
      "Math_Score         1.000000      -0.073645       0.130120         0.022948   \n",
      "Reading_Score     -0.073645       1.000000      -0.005636         0.093149   \n",
      "Writing_Score      0.130120      -0.005636       1.000000         0.010894   \n",
      "Placement_Score    0.022948       0.093149       0.010894         1.000000   \n",
      "Club_Join_Date     0.008700      -0.076759      -0.036702        -0.005781   \n",
      "\n",
      "                 Club_Join_Date  \n",
      "Math_Score             0.008700  \n",
      "Reading_Score         -0.076759  \n",
      "Writing_Score         -0.036702  \n",
      "Placement_Score       -0.005781  \n",
      "Club_Join_Date         1.000000  \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m data2corr \u001b[38;5;241m=\u001b[39m dataset2\u001b[38;5;241m.\u001b[39mcorr(method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(data2corr)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfigsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(data2corr, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoolwarm\u001b[39m\u001b[38;5;124m'\u001b[39m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "data_2018 = dataset2[dataset2['Club_Join_Date'] == 2018]\n",
    "\n",
    "data2corr = dataset2.corr(method = 'pearson')\n",
    "\n",
    "print(data2corr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(data2corr, annot=True, cmap='coolwarm', fmt='.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2acc7a-93bc-4ae2-817d-b2112552fc50",
   "metadata": {},
   "source": [
    "The variables present are not particularly correlated with each other, interestingly enough. The strongest relationships seen are between math score and writing score (r = 0.13), as well as club join date and reading date (r = -0.08). However, these relationshiops are rather weak and suggest a high degree of variance across scores and across years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0382211d-33ff-4752-bbba-dac3de173b44",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'scatter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m data_2018 \u001b[38;5;241m=\u001b[39m dataset2[dataset2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClub_Join_Date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2018\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter\u001b[49m(data_2018[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMath_Score\u001b[39m\u001b[38;5;124m'\u001b[39m], data_2018[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReading_Score\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow\n",
      "File \u001b[1;32m~\\daacs\\.venv\\Lib\\site-packages\\matplotlib\\_api\\__init__.py:217\u001b[0m, in \u001b[0;36mcaching_module_getattr.<locals>.__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m props:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m props[name]\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance)\n\u001b[1;32m--> 217\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'scatter'"
     ]
    }
   ],
   "source": [
    "data_2018 = dataset2[dataset2['Club_Join_Date'] == 2018]\n",
    "plt.scatter(data_2018['Math_Score'], data_2018['Reading_Score'])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd5fb94a-1e45-47c6-96e2-88f866baffe0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'scatter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m g1 \u001b[38;5;241m=\u001b[39m sns\u001b[38;5;241m.\u001b[39mFacetGrid(dataset2, col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClub_Join_Date\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m g1\u001b[38;5;241m.\u001b[39mmap(\u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMath_Score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWriting_Score\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m g2 \u001b[38;5;241m=\u001b[39m sns\u001b[38;5;241m.\u001b[39mFacetGrid(dataset2, col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClub_Join_Date\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m g2\u001b[38;5;241m.\u001b[39mmap(plt\u001b[38;5;241m.\u001b[39mscatter, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMath_Score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlacement_Score\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\daacs\\.venv\\Lib\\site-packages\\matplotlib\\_api\\__init__.py:217\u001b[0m, in \u001b[0;36mcaching_module_getattr.<locals>.__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m props:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m props[name]\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance)\n\u001b[1;32m--> 217\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'scatter'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g1 = sns.FacetGrid(dataset2, col=\"Club_Join_Date\")\n",
    "g1.map(plt.scatter, 'Math_Score', 'Writing_Score')\n",
    "\n",
    "g2 = sns.FacetGrid(dataset2, col=\"Club_Join_Date\")\n",
    "g2.map(plt.scatter, 'Math_Score', 'Placement_Score')\n",
    "\n",
    "g3 = sns.FacetGrid(dataset2, col=\"Club_Join_Date\")\n",
    "g3.map(plt.scatter, 'Writing_Score', 'Placement_Score')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55b9dae-4a1d-46d7-beff-a8e0e5b67e19",
   "metadata": {},
   "source": [
    "As we can see, these variables are not correlated, even within the same years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5aedb5e3-5efc-49cf-b992-6da2adc2ae31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 7.495716809785729\n",
      "Mean Absolute Error: 1.326293169377104\n",
      "R-squared Score: 0.5448242041405945\n",
      "Hours_Studied: 0.29383781196077763\n",
      "Attendance: 0.19774295147499088\n",
      "Sleep_Hours: -0.001360876408252977\n",
      "Previous_Scores: 0.04787272329518963\n",
      "Tutoring_Sessions: 0.4826961994168478\n",
      "Physical_Activity: 0.1287194026947259\n",
      "Mean Squared Error - part 2: 7.98385016954422\n",
      "Mean Absolute Error - part 2: 1.4445550157662004\n",
      "R-squared Score - part 2: 0.5151824105467476\n",
      "Hours_Studied: 0.2963309634815827\n",
      "Attendance: 0.19667754854150044\n",
      "Tutoring_Sessions: 0.4782466811626819\n",
      "Physical_Activity: 0.1214544915475457\n",
      "Mean Squared Error - part 3: 16.072718458348447\n",
      "Mean Absolute Error - part 3: 2.840523980446336\n",
      "R-squared Score - part 3: 0.023987618321983595\n",
      "Tutoring_Sessions: 0.4816777752832413\n"
     ]
    }
   ],
   "source": [
    "# Test first algorithm - Linear Regression\n",
    "\n",
    "# Choose features\n",
    "# Let's go with numeric variables - hours_studied, attendance, sleep_hours, previous_scores, tutoring_sessions, and physical_activity\n",
    "# The y-variable is test score\n",
    "X = dataset1[['Hours_Studied', 'Attendance', 'Sleep_Hours', 'Previous_Scores', 'Tutoring_Sessions', 'Physical_Activity']]\n",
    "Y = dataset1[['Exam_Score']]\n",
    "\n",
    "# Split to train and test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=28)\n",
    "\n",
    "# Create model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model with MSE\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "\n",
    "# Evaluate model with R-squared score\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "print(f'R-squared Score: {r2}')\n",
    "\n",
    "# Check coefficients of the model out of curiosity\n",
    "coefficients = model.coef_\n",
    "for i, col in enumerate(X.columns):\n",
    "    print(f\"{col}: {coefficients[0,i]}\")\n",
    "\n",
    "# The R-squared value was about 0.54, which indicates a weak relationship. \n",
    "# I removed some of the variables that were possibly less important based on coefficients.\n",
    "# We are left with hours_studied, attendance, tutoring_sessions, and physical activity.\n",
    "\n",
    "X = dataset1[['Hours_Studied', 'Attendance', 'Tutoring_Sessions', 'Physical_Activity']]\n",
    "Y = dataset1[['Exam_Score']]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=28)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "\n",
    "print(f'Mean Squared Error - part 2: {mse}')\n",
    "print(f'Mean Absolute Error - part 2: {mae}')\n",
    "\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "print(f'R-squared Score - part 2: {r2}')\n",
    "\n",
    "coefficients = model.coef_\n",
    "for i, col in enumerate(X.columns):\n",
    "    print(f\"{col}: {coefficients[0,i]}\")\n",
    "\n",
    "# That made the model worse. We will keep only tutoring sessions and test one last time.\n",
    "X = dataset1[['Tutoring_Sessions']]\n",
    "Y = dataset1[['Exam_Score']]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=28)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "\n",
    "print(f'Mean Squared Error - part 3: {mse}')\n",
    "print(f'Mean Absolute Error - part 3: {mae}')\n",
    "\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "print(f'R-squared Score - part 3: {r2}')\n",
    "\n",
    "coefficients = model.coef_\n",
    "for i, col in enumerate(X.columns):\n",
    "    print(f\"{col}: {coefficients[0,i]}\")\n",
    "\n",
    "# That was insanely worse.\n",
    "\n",
    "# As we can see, linear regression is not the best method for this data when looking at just the numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ca37c875-2ed1-40c3-a3b2-6f3fe350f312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 8.426127677475732\n",
      "Mean Absolute Error: 1.5029803845266922\n",
      "R-squared Score: 0.4883252037215614\n"
     ]
    }
   ],
   "source": [
    "# Test second algorithm Part A - Random Forest Regression\n",
    "\n",
    "# Let's go with the same numeric variables - hours_studied, attendance, sleep_hours, previous_scores, tutoring_sessions, and physical_activity\n",
    "# The y-variable is test score\n",
    "X = dataset1[['Hours_Studied', 'Attendance', 'Sleep_Hours', 'Previous_Scores', 'Tutoring_Sessions', 'Physical_Activity']]\n",
    "Y = dataset1['Exam_Score']\n",
    "\n",
    "# Split to train and test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=28)\n",
    "\n",
    "# Create model\n",
    "reg = RandomForestRegressor(n_estimators=100, random_state=15)\n",
    "reg.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions\n",
    "Y_pred = reg.predict(X_test)\n",
    "\n",
    "# Evaluate model with MSE\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "\n",
    "# Evaluate model with R-squared score\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "print(f'R-squared Score: {r2}')\n",
    "\n",
    "# Since this had an R-squared value of 0.4883, it is worse than the linear regression model.\n",
    "# It does not seem worth it to try to improve the model. Instead, we will test out random forest classification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bc16d474-3ee3-49ca-a0c8-176c645a4164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 1: 0.10835351089588378\n",
      "Accuracy 2: 0.11138014527845036\n",
      "Accuracy 3: 0.12167070217917676\n",
      "Accuracy 4: 0.11561743341404358\n",
      "Accuracy 5: 0.10956416464891042\n"
     ]
    }
   ],
   "source": [
    "# Test second algorithm Part B - Random Forest Classification\n",
    "\n",
    "# Let's go with some new variables - parental_involvement, accesss_to_resources, extracurricular_activities, \n",
    "#    motivation_level, family_income, and teacher_quality\n",
    "\n",
    "# Factorize columns\n",
    "dataset1['Parental_Involvement'] = pd.factorize(dataset1['Parental_Involvement'])[0]\n",
    "dataset1['Access_to_Resources'] = pd.factorize(dataset1['Access_to_Resources'])[0]\n",
    "dataset1['Extracurricular_Activities'] = pd.factorize(dataset1['Extracurricular_Activities'])[0]\n",
    "dataset1['Motivation_Level'] = pd.factorize(dataset1['Motivation_Level'])[0]\n",
    "dataset1['Family_Income'] = pd.factorize(dataset1['Family_Income'])[0]\n",
    "dataset1['Teacher_Quality'] = pd.factorize(dataset1['Teacher_Quality'])[0]\n",
    "\n",
    "# The y-variable is test score\n",
    "X = dataset1[['Parental_Involvement', 'Access_to_Resources', 'Extracurricular_Activities', 'Motivation_Level', 'Family_Income', 'Teacher_Quality']]\n",
    "Y = dataset1['Exam_Score']\n",
    "\n",
    "# Split to train and test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=28)\n",
    "\n",
    "# Create model\n",
    "rfClass = RandomForestClassifier(n_estimators=100, random_state=15)\n",
    "rfClass.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions\n",
    "Y_pred = rfClass.predict(X_test)\n",
    "\n",
    "# Evaluate model with accuracy score\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(f'Accuracy 1: {accuracy}')\n",
    "\n",
    "# This accuracy is horrible. I will remove variables one at a time.\n",
    "\n",
    "X = dataset1[['Parental_Involvement', 'Access_to_Resources', 'Motivation_Level', 'Family_Income', 'Teacher_Quality']]\n",
    "Y = dataset1['Exam_Score']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=28)\n",
    "\n",
    "rfClass = RandomForestClassifier(n_estimators=100, random_state=15)\n",
    "rfClass.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = rfClass.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(f'Accuracy 2: {accuracy}')\n",
    "\n",
    "X = dataset1[['Access_to_Resources', 'Motivation_Level', 'Family_Income', 'Teacher_Quality']]\n",
    "Y = dataset1['Exam_Score']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=28)\n",
    "\n",
    "rfClass = RandomForestClassifier(n_estimators=100, random_state=15)\n",
    "rfClass.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = rfClass.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(f'Accuracy 3: {accuracy}')\n",
    "\n",
    "X = dataset1[['Access_to_Resources', 'Motivation_Level', 'Teacher_Quality']]\n",
    "Y = dataset1['Exam_Score']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=28)\n",
    "\n",
    "rfClass = RandomForestClassifier(n_estimators=100, random_state=15)\n",
    "rfClass.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = rfClass.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(f'Accuracy 4: {accuracy}')\n",
    "\n",
    "X = dataset1[['Motivation_Level', 'Teacher_Quality']]\n",
    "Y = dataset1['Exam_Score']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=28)\n",
    "\n",
    "rfClass = RandomForestClassifier(n_estimators=100, random_state=15)\n",
    "rfClass.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = rfClass.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(f'Accuracy 5: {accuracy}')\n",
    "\n",
    "# Changes do not appear to help at all. This data is not helpful in predicting exam scores. Other factors must be more important in determining score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45a8df7-8a0d-4bcf-87ab-686bbec35e08",
   "metadata": {},
   "source": [
    "## Results from the Datasets\n",
    "\n",
    "### Dataset 1:\n",
    "\n",
    "It appears that linear regression and random forest models are not helpful in predicting exam scores from the provided information about students. The R-squared value for both regression problems were relatively low, around 0.5. Also, the classification algorithm provided poor accuracy at around 0.1 to 0.12 accuracy each time. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
